# Sistema Multi-Acelerador Optimizado
# CPU + iGPU Intel ARL + NPU Intel AI Boost (3720)

## ðŸŽ¯ Estrategia de DistribuciÃ³n de Carga

### 1. CPU (Ryzen/Intel - 24 cores)
**Mejor para:**
- LLMs pequeÃ±os (<3B parÃ¡metros)
- Procesamiento paralelo general
- CompilaciÃ³n, build, tareas de sistema

**ConfiguraciÃ³n:**
- Governor: performance
- Turbo boost: enabled
- SMT/HT: enabled

### 2. iGPU Intel ARL (Integrated Graphics)
**Mejor para:**
- LLMs medianos (3-7B parÃ¡metros) en Ollama
- CodificaciÃ³n de video (VAAPI/QSV)
- Tareas grÃ¡ficas ligeras

**ConfiguraciÃ³n:**
- Driver: i915 (kernel)
- OpenCL: intel-compute-runtime
- Vulkan: mesa-vulkan-drivers
- Level Zero: instalado

### 3. NPU Intel AI Boost (3720 - Meteor Lake)
**Mejor para:**
- âŒ NO para LLMs (0.97 tokens/s - 42x mÃ¡s lento)
- âœ… Embeddings (sentence-transformers, CLIP)
- âœ… ClasificaciÃ³n de texto rÃ¡pida
- âœ… Feature extraction
- âœ… DetecciÃ³n de objetos pequeÃ±os
- âœ… Tareas de inferencia edge con baja latencia

**CaracterÃ­sticas:**
- TOPS: ~10-13 TOPS (INT8)
- Memoria: Compartida con sistema
- Consumo: ~5W (muy eficiente)
- Latencia: Baja para modelos pequeÃ±os

---

## ðŸš€ Stack Recomendado

### A. LLMs (GeneraciÃ³n de texto)
```
Ollama â†’ iGPU (Vulkan) o CPU
```
- **Actual:** Ollama en iGPU con Vulkan âœ…
- **Modelos actuales:** llama3.2:3b, gemma:2b
- **NO cambiar** - funciona bien asÃ­

### B. Embeddings / RAG (Retrieval)
```
OpenVINO + NPU â†’ Modelos de embeddings
```
- **Usar:** sentence-transformers convertidos a OpenVINO IR
- **Ejemplos:**
  - all-MiniLM-L6-v2 (embeddings rÃ¡pidos)
  - multilingual-e5-small (multiidioma)
  - CLIP (imagen+texto)

### C. ClasificaciÃ³n / NLP Ligero
```
OpenVINO + NPU â†’ BERT, DistilBERT, etc.
```
- Sentiment analysis
- Named Entity Recognition (NER)
- Intent classification
- Language detection

### D. VisiÃ³n por Computadora
```
OpenVINO + NPU/iGPU â†’ YOLOv8n, MobileNet, EfficientNet
```
- DetecciÃ³n de objetos
- ClasificaciÃ³n de imÃ¡genes
- Face detection

---

## ðŸ“¦ ConfiguraciÃ³n PrÃ¡ctica

### 1. Crear servicios especializados por dispositivo
